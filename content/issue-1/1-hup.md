互联网从高速增长的莽荒纪元，逐渐过度到更智能的信息化时代。再加上人口红利的逐渐消退，人力成本也越来越高。很多公司在持续输出商业化产品的同时，对内降本增效的呼声也越来越强烈。尤其是创业十年以上的公司，早年的异构体系对研发的心智考验也越发的大。大势之下，好大夫在线技术中心也在积极应对降本增效带来的挑战，经过一年的迭代，目前已给研发团队交付了自运营平台。接下来我给大家分享一下其中的酸甜苦辣。

聊一下To-D的解决方案。

## 莽荒纪，生生不息

## 群雄割据，PaaS林立

## 顺应民意，合而为一
<!-- ## 离谱，居然差一个网址导航？ -->
[将这些痛点做出一个图]
以下场景相信大家都不陌生。咱们知道，不会偷懒的程序员，不是好的程序员，为了提效，各自发挥十八般武艺，自研小工具，所谓的PaaS层出不穷。
- 测试用例每次需要准备基境数据，那咱们就整个mock数据的小工具吧。
- 支付渠道越来越多，配置完小半天就没了，那咱们整个一键配置支付环境的小工具吧。
- 再有个小工具，能自由控制合作方域名回调测试，也是极好的。
- 如果咱们新sql从开发环境到产线环境，每一步都被验证过，将能提升稳定性，嗯，那就整个SQL PaaS平台吧。
- 对了对了，咱们经常处理消息的分发，再整个消息中间件的PaaS就完满了。
- 还不够，帮我们把项目从初始化，到最终交付产线整个流水线吧，最好能无人值守。
- ...

研发、测试、运维针对自己的日常工作，都在往自动化，智能化方向迭代。大家也享受着各种小工具带来的便利，同时又忍受着小工具带来的痛。
- 小工具的同质化，咱们知道组织架构，存在康威定律，为了减少沟通成本，往往演化出自己的一套工具链。重复的基建，也内耗了不少研发成本。
- 新员工的培训成本的增加，随着工具集的丰富，日常任务需要频繁地切换上下文，造成人力损耗。
- 随着工具集的丰富，往往在关键时刻找不到入口，更有甚者，低频的修复工具，在应急的时候，因年久失修而掉链子。

于是乎百宝箱的概念被提出来，咱们能不能把这些工具都归拢到一块，再按角色做好分类，再整合同质化的工具，这样打包放一块不就方便使用了吗?
继续之前的康威定律，前端弄了个构建平台，运维弄个了devops,测试弄了个自动化测试平台，基础架构弄了个治理平台。

到这里，提效只差一个网址导航了，再来一个首页，把各个平台的菜单展开，统一纳入进来就完美了。
[将以下内容放到一个网址导航的图片中]

网址导航，是把选择权交给了用户，罗列一堆工具链的入口。
- 有流量抓取分析的URL集合；
- 有sonar代码扫描的入口；
- 有sentry异常诊断的入口；
- 有添加短信模板的入口；
- 有提sql上线的入口等等等等。
事实上这对研发的心智要求非常高。然而在精细化分开的当下，要想了解方方面面，几乎很难做到。随着功能的堆砌，导航网址越来越多。
有时候为了解决一个问题，需要从多个入口之间不停地跳来跳去，最后我们得到了一个集多功能于一身的缝合怪。

这与我们的初衷违背，我们要的不是瑞士军刀，只要一把能生存利器而已。

这种简单的整合，其实并没有解决我们面临的真正痛点。
- 跨平台交互之间的割裂感，尤其是页面交互体验
- 重复开发的基础模块，组织架构管理模块，用户中心，消息通知模块
- 紊乱的账号体系
- 紊乱的部署形态
- 紊乱的用户交互
- 缺乏系统性，都是想到哪做到哪

这些痛点，仿佛沉淀在时间长河里的泥沙，需要来一次彻底的清理才能奔赴向前。

## 破而后立，融而为一
既然要做，那就要做的彻底，也就需要深度整合各个已经存在的平台。由于康威定律的存在，可以想象颠覆性改革，注定需要面对巨大的阻力。
为了克服困难，需要从更大的目标上对齐，把蛋糕做大，做出来的产品令人向往，才能达成共识，实现持久共赢。

### 从订立目标开始

我们的目标，围绕产品交付的整个生命周期展开，打造辅助研发测试的智能工作台，并保障稳定性和提升效率。

需要将研发测试日常工作，事件化，可视化，并能持续追踪，其实是对工作流的一种可视化，让研发测试更加聚焦具体的工作项。

![](/static/s1/1/hup_007.jpg)
图中涵盖了，业务研发运营一个服务的基本操作，我们希望新版本的效能团队，能给研发赋能，提升效率。

想象一下这个场景，A服务出现接口响应慢的告警，研发收到告警事件提醒后，打开我的工作台，他将看到到：
- 实时告警事件
- 历史流量同比环比
- 给出历史告警操作记录
- 给出最近该服务上线频次

研发就可以进行相应的常规操作，扩容，或限流，或调整告警阈值，抑或是回滚代码，当然部分操作还会发起工单审核。直接上图，大家能看的更直观。
[图、告警处理]

告警处理只是产品持续交付其中的一个小环节，可以看到实时工作台，整合了历史趋势，操作记录，上线频次，以及告警响应处理动作。
![](/static/s1/1/hup_004.png)

我们需要将这些离散的场景，抽成一个个响应事件，再串接起来，完成一项具体的工作。
后续随着数据的慢慢积累，和学习研发的操作行为，将这些经验固化到工作台中，更加智能地辅助研发做决策。


### 规划好清晰的路线

![](/static/s1/1/hup_006.png)
经过上面场景的分析，我们是围绕产品的持续交付展开的，涉及质量，安全，成本，效率等方方面面。咱们不可能一口吃个胖子，需要慢慢来，一份好的RoadMap，就像一盏指路明灯。
[图road_map]


### 快速落地基建，打响HUP第一枪

大饼画完了，就需要择个良辰吉日，动工了。2022-06-06 06:06PM，自运营工作台举行了开工仪式，投票命名HUP(haodf union platform)。为了提升信心，需要快捷完成一期基建。

这里先看一下整体拓扑。
![](/static/s1/1/hup_001.jpg)

基建，决定了平台的上限，是场景化迭代的保障。
所以一期的基建主要是通用服务的建设。接下来，我们一块了解下几个关键组件是如何协同工作的。

**单点登录(SSO)**

之前各部门自研的PaaS平台，以及引入的第三方开源平台，大部分各自实现了一套用户管理模块。当有员工入职或者离职的时候，需要各个平台保障信息的同步，带来了额外的维护成本，以及安全风险问题，统一账号体系势在必行。
先看一下拓扑图。
![](/static/s1/1/authelia.jpg)

SSO原理

从图中可以看到，实现SSO的关键组件是Authelia，我们采用的是共享顶级域的Cookie的模式来实现SSO的。

登入，基于顶级域cookie认证，必须要保证二级域名在一个域下，即*.example.net全域互通。
这些域名都需要经过SSO认证之后才能放行，二级域名首先会判断SSO特定key的cookie是否存在，是否过期，然后携带cookie去Authelia拉取用户信息。

登出，当任意一个二级域名登出的时候，调用Authelia销毁Cookie即可。


SSO优势和注意事项

- 解决了跨平台频繁登录的问题。
- 对接LDAP后，方便统一管理用户，控制权限，人员离职可一键锁定全平台的权限。
- 目前主流的开源平台都适配了LDAP，Authelia也适配了大部分的开源平台，接入成本低。
- 丰富的路由访问策略，Authelia支持免认证的白名单策略，针对高危操作配置动态二次验证等等。
- 由于实现了单点登录，带来了方便的同时，也引入了安全问题，为了避免设备被其他人操作，需要控制好cookie生命周期，失效长时间不活跃的cookie，另外关键操作需要接入动态指令的二次验证。

我们服务都部署在k8s中，通过简单配置ingress策略即可实现SSO。如果大家感兴趣。后续可以出一个单独的番外篇，详细介绍如何基于Authelia实现SSO。


**组织架构管理及权限控制**
![](/static/s1/1/hup_022.jpg)
组织架构如果靠人力维护会非常的繁杂，我们基于钉钉花名册的信息，动态生成一系列关联关系。
将现实中的部门与成员的关系，映射成不同场景的用户与分组的关联关系。人员的变更，自动维护整个组织架构体系。

![](/static/s1/1/hup_020.png)

权限控制，是各个平台的基本模块， 统一管理是基建的重中之重。
我们采用RBAC模式设计了权限管理，细化每一个请求的接口，并配置对应的菜单项，如一条告警规则的增，删，改，查，四个api对应四条菜单项。
权限控制精准到具体的api对应的菜单项上，api遵循restful规范，有get权限，未必有post权限。

![](/static/s1/1/hup_021.png)
除了api维度，还有页面维度，每个页面都配置一条路由规则，因此每个页面也对应一条菜单项，也就纳入到了权限控制中了。
根据登录用户权限的不同，会动态渲染页面，显示可操作的菜单项，如研发访问hup和测试访问hup会显示不一样的界面。

RBAC模式的不足

虽然我们已经按api的粒度去设计访问权限了，但有时候需要更细的粒度，同一个api还需要考虑参数的合法性。
比如同样是删除服务，研发只能删除自己的服务，这时候api相同，但传递的参数不同。这种目前是在后端具体的接口中做拦截的。
业内也有相应的解决方案，基于属性操作。简称ABAC(Attribute-Based Access Control)，已纳入HUP后续版本迭代规划。

另外整个权限管理，菜单配置，是基于低代码实现的，后面会介绍低代码的应用。
![](/static/s1/1/hup_019.jpg)


最后看一下组织架构设计的冰山一角，这也是首次尝试DDD(领域驱动设计)，去设计一个服务。
![](/static/s1/1/auc.jpg)

**工单体系**

做好权限控制，针对线上重要变更，就需要引入工单审核机制。工单审核，应该是一个高度抽象的模块，支持审核流的灵活配置，工单体系是场景化对接的重要基石。
![](/static/s1/1/hup_018.png)

工单体系需要解决以下几个问题：
- 按场景生成工单审核流，每一步审核都支持回滚到上一级，并清晰记录操作流程
- 审核环节支持动态和静态选择审核人，静态是明确审核人的情形，动态是指能主动选择合法的审核人，关键环节还可以支持加签，特殊情况还需要支持代批
- 审核人是一个抽象概念，可以是单个的人，也可以是多个人组成的小组
- 审核环节支持hook回调，可根据不同的审核行为触发不同的hook回调
- 工单审核流程产品化后，需要支持拖拽配置审核流，支持移动端，并联动办公交流软件，通过消息推送提醒审核人

**跨平台无缝融合**

![](/static/s1/1/hup_016.png)

我们有很多开源的平台，如绘制看板的Grafana，记录异常调用栈的Sentry，代码质量检测的Sonarqube等等，以及之前自研的内部平台。
为了避免重复造轮子，在场景化改造的时候，需要想办法复用之前的技术成果，那就涉及到跨平台交互的改造。
我们希望研发在使用HUP的时候，不要产生割裂感，不要感觉到在多个平台之间跳来跳去。
于是我们开发了一个外壳，由左导航，上导航，主体三部分组成，跨平台以主体的结构嵌入进来。
![](/static/s1/1/hup_017.jpg)
在嵌入之前，很多第三方平台有自己的登录，及导航，需要改造一下，以实现无缝嵌入。
由于我们打通了SSO单点登录，接入的平台就不需要再登录了，同时握有了登录的cookie。
我们在SSO登录的cookie里种上hup标识，第三方平台植入一段通用js，就能随意改变样式，并适配hup主题。这样第三方平台就能完美地嵌入进来了。

这种模式主要是为了嵌入第三方开源平台，或者嵌入改造成本比较高老平台，如果已经是前后端分离，那只用将前端整体迁入到HUP前端工程即可。

在基建的过程中，我们也做了不少创新，从架构到产品形态，涉及诸多方便，我们致力于打造令人兴奋的现代化的产品，为后续扩展到其他业务团队做先锋。

### 孵化前沿创新，提升HUP影响力

**开启云端开发**
![](/static/s1/1/hup_011.jpg)
传统开发是基于本地研发调试，这比较适合单体服务，这种模式在微服务架构下会面临很多问题。
- 微服务场景下，跨服务联调，需要启动多个服务，配置复杂度高，效率低。
- 各个研发本地环境可能存在差异，如node/npm版本不一致，golang pkg源设置不一致等等环境问题，干扰问题排查。
- 有时候需要多版本对比测试，需要准备多套环境，部署和运维成本都很高。
- 有时候需要debug模式启动实例，如果实例部署在k8s里，研发操作pod成本高，有些pod基础镜像甚至不支持debug能力，如果云端能和本地一样debug就方便了。

基于以上痛点，我们需要一个统一标准的开发环境，参数配置好，debug工具也安装好，研发开箱即用。这样研发只用关心业务代码，屏蔽了环境差异，那会大大提高效率。调研后，发现Nocalhost完美地解决了我们问题。

整个流程，对研发来说几乎没有什么变化。

- 研发在本地开发，文件变更后，通过IDE Plugin同步到云端为研发分配的工作空间上。
- IDE基于kubeconfig，打通研发本地和云端的通信，云端会拉起统一标准的开发环境实例，并挂载研发云端的工作目录。云端监听文件变更，实时更新服务实例。
- 云端工作空间采用共享存储，业务代码和第三方依赖分开，业务代码以研发本地机器标识隔离存储，第三方依赖为全局共享存储。
- 研发安装一个浏览器插件，通过特定的header头标识，将本地的流量劫持到云端自己的实例上，从而形成了一个闭环。

Nocalhost将研发本地开发环境迁移到了云端，并实现了流量分发的形成逻辑环。Nocalhost内置了基于k8s svc模式的路由分发，但我们后端服务注册发现是基于Eureka的，只需简单扩展一下就可以了。

**尝试GitOPS**
![](/static/s1/1/gitlab_pieline.jpg)

我们秉承着谁开发，谁治理的理念，hup体系从coding到运维，都是我们一手操办的。接入云端开发后，我们也把整个部署流程迁移到gitops。
业务代码和部署的代码分开，整体依托于gitlab pipeline。
业务代码测试通过后，打上版本tag，触发构建job和sonar扫描job。
镜像构建完成后，推送到harbor，同时更新部署仓库的镜像版本。
部署基于argocd，拉取部署仓库配置，发布到测试环境或者产线。

**看齐DDD**
![](/static/s1/1/hup_013.jpg)
基础模块，如用户中心，权限菜单管理等，属于关键支撑。
在业内也形成了领域共识，这次设计的时候也采用DDD(领域驱动设计)，同时沉淀了Golang体系的DDD框架，尝试CQRS，尝试聚合根，事件驱动。
领域内基于事件总线EventBus通信，领域间基于gRPC通信，异步操作基于消息发布订阅。为后续复杂的场景先行做理论实践。

**尝鲜前端低代码**
![](/static/s1/1/hup_014.png)
![](/static/s1/1/hup_015.png)
HUP有很多场景提供的是管理能力，基本操作也是简单的增删改查。
比如工单审核流程，列表页用表格展示待办的工单，再加一个详情页用于展示和操作。
类似的场景还是很多，比如权限配置模块，菜单配置模块，消息管理模块等等都采用了低代码实现，方便后端研发快速搭建自己的应用。
我们将百度开源的低代码平台amis，整合到了hup里。为后续其他研发部门开发业务管理后台提供了新的思路。

### 重构高频场景，提升HUP价值

随着基建的推进，HUP逐渐有具备了现代化产品的雏形，是时候上一份硬菜了。真正决定HUP平台价值的，是一个个经验固化下来的场景。
受二八规律影响，这些日常场景中，高频使用的，也就那么几个，将这些高频场景优化到极致，这时候谈论效能才更有意义。

于是我们准备选一个最高频的场景，尝试打造成范例，那就从老大难开始吧--发布工程。

重构发布工程，一年前就有过多方讨论，每次都以激烈的争论收场，得不到实质性进展。

发布工程涉及到三个小组的，多个平台的交互。运维组研发负责发布到虚拟机，架构组研发负责发布到k8s，测试阶段还对接了测试研发的自动化测试平台，中间还穿插着项目管理。
整个发布工程，处于一种能用又不好用的状态。有时候发生点问题，需要三方协调排查，效率低。
业务研发测试，完成一次从开发到产线的发布，需要在多个平台上操作，严重影响了效率。
再加上整个发布工程，经历了十多年的积淀，一直在上面打补丁，很多逻辑异常的复杂，对维护人员的心智负担巨大。

发布工程需要优化，但如何优化一直无法达成共识，有小改方案，又重构方案。其实这种项目改造属于，少做少错，多做多错，不做不错。

这个时候上层决定就尤为重要，这种跨团队协作改造，需要更高的维度对齐目标。最终在CTO的号召下，启动了发布工程的重构。
这个项目，涉及前端团队，运维团队，测试研发团队，系统架构团队多部门协作，为了保障质量和沟通效率，我们发起了封闭开发模式。
经过一个月的封闭开发，第一期重构后的发布工程和大家见面了。各个环节涉及的细节非常多，刚开始试用那两周，是被吐槽最惨的时期，慢慢走来也见证了发布工程的成长。

我们参考一下Google的发布工程哲学：
- 自服务类型，业务团队能自给自足，自己控制发布流程，同时需要高度自动化，研发只用很少的干预。
- 追求速度，敏捷开发模式，需要频繁构建，测完即能随时发布。
- 密闭性，也就是构建的幂等性，不论何时何地，构建结果应该都相同。
- 强调策略和流程，需要保障每次上线的版本，严格进行了CodeReview，都被测试验证过。

接下来一起看一下。重构后的发布工程具备了哪些特性：
- 不漏上不错上

一般发布只考虑代码变更的维度。
![](/static/s1/1/hup_023.jpg)

发布不只有代码，配置变更，线上运营操作，都属于发布范畴。而这些操作，需要被记录跟踪到，支持在开发环境，测试环境，和产线环境的回放。
改版的后的发布工程，将Code变更，Apollo配置，RabbitMQ配置，短信模板配置，脚本执行等等都纳入进来了。
![](/static/s1/1/hup_025.png)

- 支持可插拔的工作流
![](/static/s1/1/hup_002.png)
为了支持代码发布，配置变更发布，支持操作的回放，我们引入了pipeline工作流模式，来编排整个发布流程。

![](/static/s1/1/hup_008.png)
这部分挑战也是最大的，不仅需要和第三方开源平台做交互，还需要支持各个环节的热插拔。
为了将第三方开源服务接入到hup，我们开发了胶水层，封装了大量api。特殊的第三方平台，直接采用嵌入的方式集成进来。
为了支持可插拔，需要动态组装工作流，整个工作流，基于argo workflow。
发布组件用的ArgoCD，将发布模板单独抽离到一个发布仓库中，实现了业务代码合发布配置的隔离。

在工作流编排中，我们还需要适配多集群发布，支持幂等。线上有三套隔离的多活集群，一套虚拟机，两套k8s。


- 服务编排和配置编排
虽然我们鼓励业务敏捷开发，随时测试随时上线，不要有依赖，但这会增加研发向下兼容的成本。
有些时候，项目迭代涉及多个服务，需要集成到一起统一发布。因此发布工程，即需要支持业务自己独立发布，还需要支持服务编排发布的能力。
针对集成发布，我们限制于晚上特定时间发布，按南北向流量分层发布，首先发布不依赖代码的sql，apollo配置，mq配置，然后发布后端服务，再发布前端服务，最后发布脚本，同步Kong配置。
![](/static/s1/1/hup_024.jpg)

- 多版本发布，及灰度发布支持

为了适配多版本发布，我们实现了一个流量分发的逻辑环，需要适配流量入口有，http入口流量，mq消息入口流量，以及脚本入口流量。
这里给出的mq流量多版本示意。
![](/static/s1/1/hup_026.jpg)
截止目前为止灰度发布还是研发期，这里给出一个流程示意图。
![](/static/s1/1/hup_027.png)

经过几个版本的迭代，发布工程也逐渐接近毕业版本，为后续其他场景化的对接提供了可以参考的模板。
篇幅有限，这里就不展开细说，当然大家感兴趣，后续可以出了一个番外篇详细聊一下发布工程。

### 超越技术范畴，传承HUP薪火

技术从来只是基石，持续发展，受影响因素很多，往往离成功也许只差一点点运气。静下心来，慢慢打磨，有时候做着做着，也许就水到渠成了。

**效能，需要一杆秤**

![](/static/s1/1/hup_009.jpg)
场景化迭代，不只是实现某一项功能，不仅需要考虑服务于用户，还需要考虑服务于产品交付。有些场景化甚至是重新定义了研发测试部分使用习惯。

拿发布工程为例，服务上线必须经历开发环境，测试环境，最终才能到产线环境。更早的时候，开发是能跳过所有环节，直接发布到产线的，规范后的上线流程，虽然增加了上线时间，但能保障交付的产品被充分验证过。

但如果测试只想在测试环境测一项功能，就无需从开发环境再到测试环境，测试可以直接发布到测试环境，但这种发布不允许上线。

等等，发布工程做了大量的限定，从安全到效率寻找平衡点。当然这是漫长的过程，需要不断的调节，这也是目前吐槽最多的地方。


**碰撞，真正的幕后推手**

// todo fy 好产品是碰撞出来的，不是被设计出来的
HUP是好大夫服务的智能管家，管家着好大夫所有微服务的整个生命周期，从仓库代码到产线运行，以及服务治理。

这是一个庞大的体系，注定很难穷举所有场景，很难以上帝的视角提前设计好各个环节。

在前面打造产品交付流水线的时候就可以看出来，针对交付的各个环节，我们是按模块化设计的，支持动态可插拔。

跨服务交互也是基于事件发布订阅，整个生态是很多个服务组装在一起协同工作的。

我们将日常工作事件化，抽象成不同场景的工作流，配合工作流的钩子，动态调配日常工作，直到固化成一条工作经验。

[各种工作流]

**MDD，让提效看得见**
// todo 量化HUP平台价值，首先就需要量化研发和测试的价值。
<!-- 这里其实等价于，如何量化产出的问题。不仅需要量化HUP平台的价值，还需要量化研发测试的工作价值。

为了避免黑盒，我们借助于MDD思想(Metrics-Driven Development)，要求各个组件提炼出健康指标和反映内在价值的指标。
[指标上报流程图] -->

**文化自信，持续发展之道**

随着一期期的迭代，伴随着大家的吐槽，HUP快速成长，也承载着越来越多的希望。

作为平台的研发的我们，也逐渐自觉了新的身份认同--HUPer，沉淀了口号--Thinking In SRE.

HUPer做的不只是平台工具，而是在做一种企业文化，我们希望将HUP发展成一种文化符号，在不知不觉中更新大家的认知，吸纳更多的人共建生态。

我们知道产品交付，不只是发布到产线，而这恰恰只是开始，HUP作为研发测试工作台入口，势必承载了服务运营的职责，保障全站可用性和稳定性，即是职责，亦是使命。

HUPer们也在不断布道，组建线下沙龙，宣讲SRE的理念。

每一期的HUP版本迭代也会取一个代号，召开发布会，并准备周边礼品。

我们还会举办团建和周年庆，对有贡献的同学发放印有logo的文化衫，办公文具，书签等等。

慢慢地形成了一种文化传承，形成了开源的氛围，促进了HUP前行。


## 乘风破浪，征程再起

HUP目前重构了整个发布工程，完成了一阶段的交付，二阶段需要围绕交付后的服务运营展开，重新梳理SRE治理体系，提高服务的稳定性和可用性，缩短异常排查的时长。

另外一个方向，HUP目前大部分能力是基于私有云的解决方案，后续会补齐面向公有云和边缘计算的版块，为社区贡献一份自己的力量。

We are Keep running, Keep thinking.